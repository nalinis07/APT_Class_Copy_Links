{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nalinis07/APT_Class_Copy_Links/blob/MASTER/AT_Lesson_66_Class_Copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FbiXuSJANTj"
      },
      "source": [
        "# Lesson 66: Variance Inflation Factor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QN1yM4dV2Siv"
      },
      "source": [
        "### Teacher-Student Activities\n",
        "\n",
        "In the previous class, you built a linear regression model again to predict the relative humidity values from the temperature and ozone values. However, you again got `The condition number is large, 3.89e+03. This might indicate that there are strong multicollinearity or other numerical problems.` message after removing the chances of multicollinearity from the model.\n",
        "\n",
        "In this class, you will learn how to measure the extent of multicollinearity in a multiple linear regression model by calculating the variance inflation factor values for each independent variable. This exercise will enable you to select the features (or independent variables) that predicts the values of the dependent variable best. In machine learning discourse, this exercise is called **feature selection** or **feature elimination**. VIF is one of the ways to select or eliminate features to build a good linear regression model.\n",
        "\n",
        "Let's quickly run the codes covered in the previous classes and begin this session from **Activity 1: Variance Inflation Factor** section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK4-kPX3iraG"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctPdsMcc5QzN"
      },
      "source": [
        "# Run the code cell.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Loading the dataset.\n",
        "csv_file = 'https://s3-student-datasets-bucket.whjr.online/whitehat-ds-datasets/air-quality/AirQualityUCI.csv'\n",
        "df = pd.read_csv(csv_file, sep=';')\n",
        "\n",
        "# Dropping the 'Unnamed: 15' & 'Unnamed: 16' columns.\n",
        "df = df.drop(columns=['Unnamed: 15', 'Unnamed: 16'], axis=1)\n",
        "\n",
        "# Dropping the null values.\n",
        "df = df.dropna()\n",
        "\n",
        "# Creating a Pandas series containing 'datetime' objects.\n",
        "dt_series = pd.Series(data = [item.split(\"/\")[2] + \"-\" + item.split(\"/\")[1] + \"-\" + item.split(\"/\")[0] for item in df['Date']], index=df.index) + ' ' + pd.Series(data=[str(item).replace(\".\", \":\") for item in df['Time']], index=df.index)\n",
        "dt_series = pd.to_datetime(dt_series)\n",
        "\n",
        "# Remove the Date & Time columns from the DataFrame and insert the 'dt_series' in it.\n",
        "df = df.drop(columns=['Date', 'Time'], axis=1)\n",
        "df.insert(loc=0, column='DateTime', value=dt_series)\n",
        "\n",
        "# Get the Pandas series containing the year values as integers.\n",
        "year_series = dt_series.dt.year\n",
        "\n",
        "# Get the Pandas series containing the month values as integers.\n",
        "month_series = dt_series.dt.month\n",
        "\n",
        "# Get the Pandas series containing the day values as integers.\n",
        "day_series = dt_series.dt.day\n",
        "\n",
        "# Get the Pandas series containing the days of a week, i.e., Monday, Tuesday, Wednesday etc.\n",
        "day_name_series = dt_series.dt.day_name()\n",
        "\n",
        "# Add the 'Year', 'Month', 'Day' and 'Day Name' columns to the DataFrame.\n",
        "df['Year'] = year_series\n",
        "df['Month'] = month_series\n",
        "df['Day'] = day_series\n",
        "df['Day Name'] = day_name_series\n",
        "\n",
        "# Sort the DataFrame by the 'DateTime' values in the ascending order. Also, display the first 10 rows of the DataFrame.\n",
        "df = df.sort_values(by='DateTime')\n",
        "\n",
        "# Create a function to replace the commas with periods in a Pandas series.\n",
        "def comma_to_period(series):\n",
        "    new_series = pd.Series(data=[float(str(item).replace(',', '.')) for item in series], index=df.index)\n",
        "    return new_series\n",
        "\n",
        "# Apply the 'comma_to_period()' function on the ''CO(GT)', 'C6H6(GT)', 'T', 'RH' and 'AH' columns.\n",
        "cols_to_correct = ['CO(GT)', 'C6H6(GT)', 'T', 'RH', 'AH'] # Create a list of column names.\n",
        "for col in cols_to_correct: # Iterate through each column\n",
        "    df[col] = comma_to_period(df[col]) # Replace the original column with the new series.\n",
        "\n",
        "# Remove all the columns from the 'df' DataFrame containing more than 10% garbage value.\n",
        "df = df.drop(columns=['NMHC(GT)', 'CO(GT)', 'NOx(GT)', 'NO2(GT)'], axis=1)\n",
        "\n",
        "# Create a new DataFrame containing records for the years 2004 and 2005.\n",
        "aq_2004_df = df[df['Year'] == 2004]\n",
        "aq_2005_df = df[df['Year'] == 2005]\n",
        "\n",
        "# Replace the -200 value with the median values for each column having indices between 1 and -4 (excluding -4) for the 2004 year DataFrame.\n",
        "for col in aq_2004_df.columns[1:-4]:\n",
        "  median = aq_2004_df.loc[aq_2004_df[col] != -200, col].median()\n",
        "  aq_2004_df[col] = aq_2004_df[col].replace(to_replace=-200, value=median)\n",
        "\n",
        "# Repeat the same exercise for the 2005 year DataFrame.\n",
        "for col in aq_2005_df.columns[1:-4]:\n",
        "  median = aq_2005_df.loc[aq_2005_df[col] != -200, col].median()\n",
        "  aq_2005_df[col] = aq_2005_df[col].replace(to_replace=-200, value=median)\n",
        "\n",
        "# Group the DataFrames about the 'Month' column.\n",
        "group_2004_month = aq_2004_df.groupby(by='Month')\n",
        "group_2005_month = aq_2005_df.groupby(by='Month')\n",
        "\n",
        "# Concatenate the two DataFrames for 2004 and 2005 to obtain one DataFrame.\n",
        "df = pd.concat([aq_2004_df, aq_2005_df])\n",
        "\n",
        "# Information of the DataFrame.\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpefFKryHnV_"
      },
      "source": [
        "The description for all the columns containing data for air pollutants, temperature, relative humidity and absolute humidity is provided below.\n",
        "\n",
        "\n",
        "|Columns|Description|\n",
        "|-|-|\n",
        "|PT08.S1(CO)|PT08.S1 (tin oxide) hourly averaged sensor response (nominally $\\text{CO}$ targeted)|\n",
        "|C6H6(GT)|True hourly averaged Benzene concentration in $\\frac{\\mu g}{m^3}$|\n",
        "|PT08.S2(NMHC)|PT08.S2 (titania) hourly averaged sensor response (nominally $\\text{NMHC}$ targeted)|\n",
        "|PT08.S3(NOx)|PT08.S3 (tungsten oxide) hourly averaged sensor response (nominally $\\text{NO}_x$ targeted)|\n",
        "|PT08.S4(NO2)|PT08.S4 (tungsten oxide) hourly averaged sensor response (nominally $\\text{NO}_2$ targeted)|\n",
        "|PT08.S5(O3) |PT08.S5 (indium oxide) hourly averaged sensor response (nominally $\\text{O}_3$ targeted)|\n",
        "|T|Temperature in √Ç¬∞C|\n",
        "|RH|Relative Humidity (%)|\n",
        "|AH|AH Absolute Humidity|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsKszxp14Cj8"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6myfsJox3Tz2"
      },
      "source": [
        "#### Multiple Linear Regression Model Using `sklearn` Module\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8d5faFMdTvz"
      },
      "source": [
        "# Build a linear regression model using the sklearn module by including all the features listed above.\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "features = list(df.columns.values[1:-1])\n",
        "features.remove('RH')\n",
        "\n",
        "X = df[features]\n",
        "y = df['RH']\n",
        "\n",
        "# Splitting the DataFrame into the train and test sets.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42) # Test set will have 33% of the values.\n",
        "\n",
        "y_train_reshaped = y_train.values.reshape(-1, 1)\n",
        "y_test_reshaped = y_test.values.reshape(-1, 1)\n",
        "\n",
        "# Build a linear regression model using the 'sklearn.linear_model' module.\n",
        "sklearn_lin_reg = LinearRegression()\n",
        "sklearn_lin_reg.fit(X_train, y_train_reshaped)\n",
        "\n",
        "# Print the value of the intercept i.e. beta-sub-0.\n",
        "print(\"\\nConstant\".ljust(15, \" \"), f\"{sklearn_lin_reg.intercept_[0]:.6f}\") # Soon you will get to know why rounding-off to 6 decimal places.\n",
        "\n",
        "# Print the names of the features along with the values of their corresponding coefficients.\n",
        "for item in list(zip(X.columns.values, sklearn_lin_reg.coef_[0])):\n",
        "  print(f\"{item[0]}\".ljust(15, \" \"), f\"{item[1]:.6f}\") # Soon you will get to know why rounding-off to 6 decimal places."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BxonYJweOlM"
      },
      "source": [
        "# Evaluate the linear regression model using the 'r2_score', 'mean_squared_error' & 'mean_absolute_error' functions of the 'sklearn' module.\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "y_train_pred = sklearn_lin_reg.predict(X_train)\n",
        "y_test_pred = sklearn_lin_reg.predict(X_test)\n",
        "\n",
        "print(f\"Train Set\\n{'-' * 50}\")\n",
        "print(f\"R-squared: {r2_score(y_train_reshaped, y_train_pred):.3f}\")\n",
        "print(f\"Mean Squared Error: {mean_squared_error(y_train_reshaped, y_train_pred):.3f}\")\n",
        "print(f\"Root Mean Squared Error: {np.sqrt(mean_squared_error(y_train_reshaped, y_train_pred)):.3f}\")\n",
        "print(f\"Mean Absolute Error: {mean_absolute_error(y_train_reshaped, y_train_pred):.3f}\")\n",
        "\n",
        "print(f\"\\n\\nTest Set\\n{'-' * 50}\")\n",
        "print(f\"R-squared: {r2_score(y_test_reshaped, y_test_pred):.3f}\")\n",
        "print(f\"Mean Squared Error: {mean_squared_error(y_test_reshaped, y_test_pred):.3f}\")\n",
        "print(f\"Root Mean Squared Error: {np.sqrt(mean_squared_error(y_test_reshaped, y_test_pred)):.3f}\")\n",
        "print(f\"Mean Absolute Error: {mean_absolute_error(y_test_reshaped, y_test_pred):.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr6JYLj5R2ZL"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1Hdc-pvye7r"
      },
      "source": [
        "#### The `statsmodels.api` Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyeNqK74emeV"
      },
      "source": [
        "# Build a linear regression model using the 'statsmodels.api' module.\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Create data frames for the features and target again and also split them into the train and test sets.\n",
        "X = df[features]\n",
        "y = df['RH']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42) # Test set will have 33% of the values.\n",
        "\n",
        "# Add a constant to get an intercept\n",
        "X_train_sm = sm.add_constant(X_train)\n",
        "\n",
        "# Fit the regression line using 'OLS'\n",
        "lr = sm.OLS(y_train, X_train_sm).fit()\n",
        "\n",
        "# Print the parameters, i.e. the intercept and the slope of the regression line fitted\n",
        "lr.params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxdMWw-EObIa"
      },
      "source": [
        "The above values for the constant and the coefficients of all the features are almost the same as the ones obtained through the `sklearn` linear regression model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xsgOhbGeyEI"
      },
      "source": [
        "# Performing a summary operation lists out all the different parameters of the regression line fitted\n",
        "print(lr.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvLFbvlMkYYU"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ku5Z-Tz2NB9d"
      },
      "source": [
        "#### Multicollinearity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcBSxFC2Lepf"
      },
      "source": [
        "# Print the summary of the multiple linear regression model built earlier.\n",
        "print(lr.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jp5IzGDIYPml"
      },
      "source": [
        "Multicollinearity is a situation where the independent variables or features are correlated to each other. Ideally, only the dependent variable (or target) should be correlated with the independent variables and the independent variables should not be correlated with each other at all.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmC7VsyYbh6s"
      },
      "source": [
        "# Create a heatmap of a correlation DataFrame of the air quality analysis dataset to understand this concept better.\n",
        "plt.figure(figsize = (12, 6), dpi = 96)\n",
        "sns.heatmap(df.corr(), annot = True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgmAgVJjUfJ5"
      },
      "source": [
        "From the heatmap, you can see that, the dependent variable `RH` is moderately correlated with `T` and weakly correlated with carbon monoxide (`'PT08.S1(CO)'`), ozone (`'PT08.S5(O3)'`) , absolute humidity (`AH`) and year (`Year`).\n",
        "\n",
        "Ideally, to build a multiple linear regression model to predict relative humidity, we should have considered carbon monoxide, ozone, absolute humidity and year independent variables only instead of considering all the independent variables. But among these 4 features:\n",
        "\n",
        "- carbon monoxide and ozone are strongly correlated to each other.\n",
        "\n",
        "- temperature and absolute humidity are moderately correlated to each other.\n",
        "\n",
        "- temperature and year are moderately correlated to each other.\n",
        "\n",
        "- absolute humidity and year are moderately correlated to each other.\n",
        "\n",
        "The above four cases are examples of multicollinearity wherein the independent variables are correlated to each other.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nFo4VBqZSoY"
      },
      "source": [
        "# Create a correlation heatmap between 'RH', 'T', 'PT08.S1(CO)', 'PT08.S5(O3)', 'AH', 'Year' variables.\n",
        "plt.figure(figsize = (6, 4), dpi = 96)\n",
        "sns.heatmap(df[['RH', 'T', 'PT08.S1(CO)', 'PT08.S5(O3)', 'AH', 'Year']].corr(), annot = True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ToDUMHaaAin"
      },
      "source": [
        "This multicollienarity causes redundancy because of which we cannot say for sure which of the independent variables are actually contributing to the prediction of the dependent variable.\n",
        "\n",
        "In this case, to remove multicollinearity,\n",
        "\n",
        "- Choose either `T` or `AH` as one of the independent variables. Since the correlation between `RH` and `T` is stronger compared to the correlation between `RH` and `AH`, let's choose `T`.\n",
        "\n",
        "- Choose either `'PT08.S1(CO)'` or `'PT08.S5(O3)'` as one of the independent variables. Since the correlation between `RH` and `PT08.S5(O3)` is stronger compared to the correlation between `RH` and `'PT08.S1(CO)'`, let's choose `PT08.S5(O3)`.\n",
        "\n",
        "- Drop `Year` as it is moderately correlated with `'T'`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsQPQ5hjklEo"
      },
      "source": [
        "# Create a correlation heatmap between 'RH', 'T', 'PT08.S5(O3)' variables.\n",
        "plt.figure(figsize = (6, 4), dpi = 96)\n",
        "sns.heatmap(df[['RH', 'T', 'PT08.S5(O3)']].corr(), annot = True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbC9a-WuxSVJ"
      },
      "source": [
        "Now that we have removed multicollinearity and selected the features that are likely to contribute best to the prediction of relative humidity values, let's build a linear regression model again using the `statsmodels.api` module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRwLZRNvpshr"
      },
      "source": [
        "# Build a linear regression model again with 'T' and 'PT08.S5(O3)' as independent variables to predict 'RH'.\n",
        "X_train = X_train[['T', 'PT08.S5(O3)']]\n",
        "X_test = X_test[['T', 'PT08.S5(O3)']]\n",
        "\n",
        "# Add a constant to get an intercept\n",
        "X_train_sm1 = sm.add_constant(X_train)\n",
        "\n",
        "# Fit the regression line using 'OLS'\n",
        "lr1 = sm.OLS(y_train, X_train_sm1).fit()\n",
        "\n",
        "# Print the parameters, i.e. the intercept and the slope of the regression line fitted\n",
        "lr1.params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjrz3ajhySFj"
      },
      "source": [
        "Let's now print the summary table as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giR8Kjj-GrUC"
      },
      "source": [
        "df['PT08.S5(O3)'].std() / np.sqrt(df['PT08.S5(O3)'].mean())\n",
        "print(df['T'].std() / np.sqrt(df['T'].mean()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcHrgo8ZrjuR"
      },
      "source": [
        "# Print the summary table to get all the parameters for the features used to build a linear regression model.\n",
        "print(lr1.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmCdGwirtOkt"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_bA8KTPt4is"
      },
      "source": [
        "#### Activity 1: Variance Inflation Factor Math\n",
        "\n",
        "Variance Infation Factor (VIF) is a way to detect multicollinearity between independent variables in a dataset. We calculate the VIF values to measure the extent of multicollinearity between the independent variables.  \n",
        "\n",
        "For $k$ different independent variables, we can calculate $k$ different VIFs (one for each $x_i$ where $i = 1, 2, 3, \\dots, k$) in three steps:\n",
        "\n",
        "**Step one**\n",
        "\n",
        "First, build a multiple linear regression model wherein $x_i$ is a target variable and it is a function of all the other feature variables as illustrated in the equation below.\n",
        "\n",
        "$$x_1 = \\beta_0^* + \\beta_2^* x_2 + \\beta_3^* x_3 + \\beta_4^* x_4 + \\dots + \\beta_k^* x_k + \\epsilon^*$$\n",
        "\n",
        "Here,\n",
        "\n",
        "- $x_1$ is a feature acting as the target (or dependent) variable in above equation\n",
        "\n",
        "- $x_2, x_3, x_4, \\dots , x_k$ are independent variables or features\n",
        "\n",
        "- $\\beta_0^*, \\beta_2^*, \\beta_3^*, \\dots, \\beta_k^*$ are the corresponding regression coefficients of the independent variables in the above linear regression equation\n",
        "\n",
        "- **$\\epsilon^*$** is the random error obtained along with the predicted value\n",
        "\n",
        "**Step two**\n",
        "\n",
        "Then, calculate the VIF for $x_{i}$ using the following formula:\n",
        "\n",
        "$$\\text{VIF}_{i} = \\frac{1}{1-R_{i}^{2}}$$\n",
        "\n",
        "where $R^2 _i$ is the coefficient of determination of the regression equation in step one, with $x_{1}$ on the left hand side, and all other independent variables on the right hand side.\n",
        "\n",
        "**Step three**\n",
        "\n",
        "Analyse the extent of multicollinearity by considering the magnitude of the $\\text{VIF}_{i}$. **A rule of thumb is that if $\\text{VIF}_{i} > 10$, then multicollinearity is high. In that case, the $x_i$ feature must be dropped to predict the values of the target (or dependent) variable.** A cutoff of 5 is also commonly used.\n",
        "\n",
        "Let's learn this concept with the help of an example. Let's build a linear regression model to predict relative humidity values from `T` and `PT08.S5(O3)`\tvalues. Let's add one more feature say `'PT08.S1(CO)'` to the prediction mode because ozone and carbon monoxide are highly correlated to each other and relative humidity is correlated to carbon monoxide as well.\n",
        "\n",
        "Then we will calculate the VIF values for `T, PT08.S5(O3)` and `'PT08.S1(CO)'` independent variables first using the `variance_inflation_factor` function of the `statsmodels.stats.outliers_influence` module and then using $\\frac{1}{1 - R^2}$ formula.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqoZb1AZ9Yix"
      },
      "source": [
        "# S1.1: Build a linear regression model again with 'T', 'PT08.S5(O3)' and 'PT08.S1(CO)' as independent variables to predict 'RH'.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Jp_Z90jCJhd"
      },
      "source": [
        "# S1.2: Print the summary table for the above linear regression model.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UqA-3sIJ9HB"
      },
      "source": [
        "Now let's calculate the VIF values for `'T', 'PT08.S5(O3)'` and `'PT08.S1(CO)'` independent variables using the `variance_inflation_factor` function of the `statsmodels.stats.outliers_influence` module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BN2VdS-TCSBz"
      },
      "source": [
        "# S1.3: Calculate the VIF values for 'T', 'PT08.S5(O3)' and 'PT08.S1(CO)' independent variables using the 'variance_inflation_factor' function.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYzQDuuxCVe9"
      },
      "source": [
        "As you can see the VIF values for carbon monoxide and ozone are very high.\n",
        "\n",
        "Let's learn how to calculate the VIF values using the $\\frac{1}{1 - R^2}$ formula. But before that, let's build a linear regression model again taking ozone as the dependent variable and temperature and carbon monoxide as the independent variables. Then calculate the $R^2$ value for this model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hs447BDCCtsr"
      },
      "source": [
        "# S1.4: Build a linear regression model taking 'PT08.S5(O3)' as the target and 'T' and 'PT08.S1(CO)' as the independent variables.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saha-qjaD0Vu"
      },
      "source": [
        "# S1.5: Calculate the VIF value for ozone where ozone is the dependent variable.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ub30g5nRfWr"
      },
      "source": [
        "Now, let's repeat the above two exercises to calculate the VIF value for `T` independent variable using the $\\frac{1}{1 - R^2}$ variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qyKhLM3HoMQ"
      },
      "source": [
        "# S1.6: Build a linear regression model taking 'T' as the target and 'T' and 'PT08.S1(CO)' and 'PT08.S5(O3)' as the independent variables.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OuTwffeIvUm"
      },
      "source": [
        "# S1.7: Calculate the VIF value for temperature where temperature is the dependent variable.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btJ4p4azcu6l"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHqazoarSQX_"
      },
      "source": [
        "#### Activity 2: Calculating VIFs for Previously Built Model\n",
        "\n",
        "Now let's calculate the VIF values for the independent variables in the linear regression model that you built in the previous class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eFjXjIJScdk"
      },
      "source": [
        "# S2.1: Calculate the VIF values for the independent variables in the linear regression model built in the previous class.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvIe0nn_S7A7"
      },
      "source": [
        "Here, the `const` (short for **constant**) is an additional feature that we add before building a linear regression module. It has all the values as $1$. So, `const` is causing multicollinearity.\n",
        "\n",
        "Ideally, we should drop `const` because the VIF value for it is greater than 10. But we cannot drop it, because using this feature we get the $\\beta_0$ value.\n",
        "\n",
        "So now let's look at the final linear regression model that we have built after selecting the final features that are supposed to predict the relative humidity values.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrjjdx7FUkta"
      },
      "source": [
        "# S2.2: Print the summary table for the linear regression model built in the previous class by taking 'T' and 'PT08.S5(O3)' as features.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUpsQ2RQVGW_"
      },
      "source": [
        "Hence, to predict relative humidity values, the final linear regression model that you get after going through so much effort is\n",
        "\n",
        "$$\\text{relative humidity} = 64.9564 - 1.1043 \\space{} \\text{temperature} + 0.0045 \\space{} \\text{ozone}$$\n",
        "\n",
        "or\n",
        "\n",
        "$$\\text{RH} = 64.9564 - 1.1043 \\space{} \\text{T} + 0.0045 \\space{} \\text{O}_3$$\n",
        "\n",
        "You can create a function that can predict relative humidity values using the temperature and ozone values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkzzeAkOWLPM"
      },
      "source": [
        "# S2.3: Create a function that can predict relative humidity values using the temperature and ozone values.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhueD8RwZmAG"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seQ9QNJjZPK5"
      },
      "source": [
        "#### Activity 3: Rebuilding Linear Regression Model Using The `sklearn` Module\n",
        "\n",
        "Let's rebuild the above linear regression model again using the `sklearn` module and then print $R^2$, MSE, RMSE and MAE values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Hq1YYx1X1sT"
      },
      "source": [
        "# S3.1: Rebuild the above linear regression model again using the sklearn module and then print  ùëÖ2 , MSE, RMSE and MAE values.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mch3679WZze3"
      },
      "source": [
        "Now let's evaluate the linear regression model using the $R^2$, MSE, RMSE and MAE values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFxDV6fbYygl"
      },
      "source": [
        "# S3.2: Evaluate the linear regression model using the 'r2_score', 'mean_squared_error' & 'mean_absolute_error' functions of the 'sklearn' module.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqpc033MZ74u"
      },
      "source": [
        "As you can see, there is hardly any improvement in the performance of the linear regression model after considering ozone as another independent variables to predict the relative humidity values. Hence, we can conclude either of the following from this result:\n",
        "\n",
        "1. In general, the relative humidity values cannot be predicted accurately using temperature and ozone.\n",
        "\n",
        "2. In particular, the linear regression model cannot accurately predict the relative humidity values from the ozone and temperature values.\n",
        "\n",
        "It might happen many a times that a particular problem cannot be solved using a particlar machine learning algorithm. Hence, you might have to use other algorithms to solve that problem. By experience i.e. by solving more and more problems, you will learn to apply the most appropriate machine learning algorithm to solve a problem.\n",
        "\n",
        "Let's stop here. In the next class, we will solve another problem statement in which linear regression predicts the outcomes more accurately and is best suited for it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9ca8HNkt327"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDTXyuVVqSHc"
      },
      "source": [
        "### **Project**\n",
        "You can now attempt the **Capstone Project - Diamond Price Prediction** on your own.\n",
        "\n",
        "**Capstone Project - Diamond Price Prediction**: https://colab.research.google.com/drive/1YP4OiSvsLVur_2GbEcCnbugflUXrlJP-?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCC0K2aNqd7Q"
      },
      "source": [
        "---"
      ]
    }
  ]
}
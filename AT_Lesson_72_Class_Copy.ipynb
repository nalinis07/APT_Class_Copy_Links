{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nalinis07/APT_Class_Copy_Links/blob/MASTER/AT_Lesson_72_Class_Copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q61PZrHf6Upi"
      },
      "source": [
        "# Lesson 72: Logistic Regression - Univariate Classification I"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze9uSJt-I-0E"
      },
      "source": [
        "### Teacher-Student Activities\n",
        "\n",
        "In the previous classes, you have already worked on the **heart disease dataset** where you calculated the probability of a person having heart disease by examining the `chol` (cholesterol) values. The results roughly suggested that people with less cholesterol level have greater chances of heart disease and people with high cholesterol level have lesser chances of heart disease.\n",
        "\n",
        "\n",
        "Here's the box plot that we created in the previous classes to visualise the distribution of the `chol` values.\n",
        "\n",
        "<img src = 'https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/heart-disease-boxplot.png' width = 1000>\n",
        "\n",
        "From the box plot, you can observe that the first, second and third quartiles of the cholesterol values for the patients **having** heart disease (shown with the orange colour) are lower as compared to the ones for the patients **not having** it (shown with the blue colour).\n",
        "\n",
        "Hence, we concluded that people having lower cholesterol levels are more likely to have heart disease.\n",
        "\n",
        "In today's class, you will learn to classify or predict whether a person is suffering from heart disease or not based on just cholesterol values by deploying two most commonly used classification-based machine learning algorithms:\n",
        "\n",
        "1. Random Forest Classifier\n",
        "2. Logistic Regression\n",
        "\n",
        "Before we start, let's first recall the attributes or columns of the dataset.\n",
        "\n",
        "**Data Description**\n",
        "\n",
        "The Heart Disease UCI dataset contains data collected on 14 different attributes by examining 303 patients. The dataset focuses only on differentiating patients having heart disease; labelled as value 1 and those not having heart disease; labelled as value 0. The 14 attributes (or columns) are as follows:\n",
        "\n",
        "|Columns|Description|\n",
        "|-|-|\n",
        "|age|age in years|\n",
        "|sex|sex (1 = male; 0 = female)|\n",
        "|cp|chest pain type (4 values)|\n",
        "|trestbps|resting blood pressure (in mm Hg on admission to the hospital)|\n",
        "|chol|serum cholesterol in $\\frac{mg}{dl}$|\n",
        "|fbs|fasting blood sugar > 120 $\\frac{mg}{dl}$|\n",
        "|restecg|resting electrocardiographic results (values 0, 1, 2)|\n",
        "|thalach|maximum heart rate achieved|\n",
        "|exang|exercise induced angina (1 = yes; 0 = no)|\n",
        "|oldpeak|ST depression induced by exercise relative to rest|\n",
        "|slope|the slope of the peak exercise ST segment|\n",
        "|ca|number of major vessels (0-3) colored by fluoroscopy|\n",
        "|thal|A blood disorder called thalassemia|\n",
        "|target|1 = presence of heart disease; 0 = absence of heart disease|\n",
        "\n",
        "**Source:** https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpKI2pWEtREK"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2UBkl1AZuRc"
      },
      "source": [
        "#### Activity 1: Loading Data\n",
        "\n",
        "Load the heart disease dataset. Here's the dataset link:\n",
        "\n",
        "https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/whitehat-ds-datasets/uci-heart-disease/heart.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmRB05lddS--"
      },
      "source": [
        "# S1.1: Import the required modules and load the heart disease dataset. Also, display the first five rows.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1a-clG-jqPr"
      },
      "source": [
        "Let's first look at the complete information on the `df` DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2x3F5XtkAGd"
      },
      "source": [
        "# S1.2: Apply the 'info()' function on the 'df' DataFrame.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgnxI54ckEb6"
      },
      "source": [
        "You can see there are 303 entries for each column and no missing values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Al16HfwffBFB"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dpw7DeLczN3f"
      },
      "source": [
        "#### Activity 2: Imbalanced Data^\n",
        "\n",
        "The target variable `target` has two values: `0` and `1`. This means that our dataset is composed of two classes or labels:\n",
        "\n",
        " - Class `0` - Patients NOT having heart disease\n",
        " - Class `1` - Patients having heart disease\n",
        "\n",
        "Such problems are known as **binary classification** problem where the target attribute can have only two possible values (for e.g. `0` and `1`).\n",
        "\n",
        "Before we start building the model, let us find out whether our dataset is balanced or not i.e. whether class distribution is uniform among all the classes. An imbalanced dataset means that the number of observations belonging to one class is significantly lower than that of the other class. Such datasets will result in a biased classifier which will hamper the results.\n",
        "\n",
        "As our dataset has two classes, then balanced data would mean 50% observations for each class. Let us calculate the number of observations for each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEVBxNQQThSd"
      },
      "source": [
        "# S2.1 Print the number of records in each label and their percentage in the 'target' column\n",
        "# Print the number of records with and without heart disease\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxfijABxvgSG"
      },
      "source": [
        "You can observe that the number of observations for each class is approximately 54% and 46% which does not seems one-sided. This means that our dataset is not imbalanced or biased towards one class or label.\n",
        "\n",
        "Let us classify the patients using Random Forest Classifier and evaluate the prediction model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eymgp4JPjDNa"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AFcyIZMSl07"
      },
      "source": [
        "#### Activity 3: Train-Test Split\n",
        "\n",
        "We will first predict whether a person is a heart patient or not by analysing only his/her cholesterol value. Thus, the model will use only one feature or independent variable `chol` to predict the target variable `target`.\n",
        "\n",
        "Before deploying our model, let's split the `df` DataFrame into train set and test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYoe69GREXWK"
      },
      "source": [
        "# S3.1: Split the DataFrame into the train and test sets.\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5zYRSClwqFY"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20N4v1sjMgGU"
      },
      "source": [
        "#### Activity 4: Applying Random Forest Classifier^^\n",
        "\n",
        "We had already explored the **Random Forest Classifier** algorithm in one of our previous classes. Let's use it to find out if it can detect the patients having heart disease accurately or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4cMnv2jyQGz"
      },
      "source": [
        "# S4.1: Build the Random Forest Classifier prediction model.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPO9njW_xwS1"
      },
      "source": [
        "You may observe that the model score is pretty close to 1 or 100%. Let's perform predictions using the above model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylnKkzbrT6Jr"
      },
      "source": [
        "# S4.2: Make predictions on the test dataset using the 'predict()' function.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaoPJ7hGUBco"
      },
      "source": [
        "Let's compute the confusion matrix to evaluate the accuracy of our classifier `rf_clf`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_kCRRwloRd-"
      },
      "source": [
        "# S4.3: Display the results of 'confusion_matrix'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96m-xTok2-tt"
      },
      "source": [
        "So we got the confusion matrix for our Random Forest model. Let's recall what does a confusion matrix returns as output.\n",
        "\n",
        "In this case,\n",
        " - positive outcome $\\Rightarrow$ class `1` (patients having heart disease)\n",
        " - negative outcome $\\Rightarrow$ class `0` (patients NOT having heart disease)\n",
        "\n",
        "The confusion matrix reflects the following values:\n",
        "\n",
        "1. **True Negatives (TN)** - class `0` values **correctly** predicted as class `0`.\n",
        "\n",
        "2. **True Positives (TP)** - class `1` values **correctly** predicted as class `1`.\n",
        "\n",
        "3. **False Positives (FP)** - class `0` values **incorrectly**  predicted as class `1`.\n",
        "\n",
        "4. **False Negatives (FN)** - class `1` values **incorrectly**  predicted as class `0`.\n",
        "\n",
        "\n",
        "||Predicted Class `0`|Predicted Class `1`|    \n",
        "|-|-|-|\n",
        "|Actual Class `0`|**TN = 24**|**FP = 17**|\n",
        "|Actual Class `1`|**FN = 20**|**TP = 30**|\n",
        "\n",
        "\n",
        "**Note:** Every time you build a prediction model, the predictions might be slightly different from the previous ones. Hence, the confusion matrix might have slightly different values every time.\n",
        "\n",
        "These values of confusion matrix are used for calculating precision, recall and f1-score with the below formulae:\n",
        "\n",
        "1. **Precision** - It is the ratio of the correctly predicted positive values (TP) to the total predicted positive values (TP + FP) i.e.\n",
        "\n",
        "$$\\text{precision} = \\frac{\\text{TP}}{\\text{TP + FP}}$$\n",
        "\n",
        "\n",
        "2. **Recall** -  It is the ratio of the correctly predicted positive values (TP)values to the total values (TP + FN) i.e.\n",
        "\n",
        "$$\\text{recall} = \\frac{\\text{TP}}{\\text{TP + FN}}$$\n",
        "\n",
        "\n",
        "3. **f1-score** - It is a harmonic mean of the precision and recall values, i.e.\n",
        "\n",
        "$$\\text{f1-score} = 2 \\left( \\frac{\\text{precision} \\times \\text{recall}}{\\text{precision} + \\text{recall}} \\right)$$\n",
        "\n",
        "Let's take a look at precision, recall and f1-score of our model using `classification_report()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMH7f---UTVy"
      },
      "source": [
        "# S4.4: Display the precision, recall and f1-score values.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ4fM1guUjtr"
      },
      "source": [
        "We can see that the **f1-scores** for both the labels `0` and `1` are not closed to 1. Thus, the prediction percentage is not satisfactory.  \n",
        "\n",
        "Let's verify accuracy with another classification based machine learning model **Logistic Regression**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxrVzP-_0kah"
      },
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_poi12der_F"
      },
      "source": [
        "#### Activity 5: Logistic Regression^^^\n",
        "\n",
        "Logistic Regression is a type of **classification** algorithm which classifies or categorises a given set of data into different class labels. In the context of heart disease dataset, logistic regression will  classify the patients either as `1` (having heart disease) or as `0` (not having heart disease).\n",
        "\n",
        "Logistic Regression is used to predict the probability of an outcome for an event. It calculates a threshold probability value. If the probability of an outcome is less than the threshold probability, then logistic regression classifies that outcome as `0`, otherwise as `1`. You will learn the technical details in the subsequent classes, but for the time being, let's build a Logistic Regression model on the train set by following the steps listed below:\n",
        "\n",
        "1. Import `LogisticRegression` class from the `sklearn.linear_model` module.\n",
        "2. Create an object of the `LogisticRegression` class, say `log_reg` and pass `n_jobs = -1` as input to its constructor.\n",
        "3. Call the `fit()` function of the `LogisticRegression` class on the object created and pass `X_train` and `y_train` as inputs to the function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxtlCGgAeUkl"
      },
      "source": [
        "# T5.1: Deploy the 'LogisticRegression' model using the 'fit()' function.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXuBKlKC0EE5"
      },
      "source": [
        "The accuracy score is less than the one obtained through `RandomForestClassifier` . However, let's make the predictions on the test set and compare them with the actual labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JMQlyNOfDAq"
      },
      "source": [
        "# S5.1: Make predictions on the test dataset by using the 'predict()' function.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUWZiyrF0EE-"
      },
      "source": [
        "Let's compute the confusion matrix to calculate recall, precision and f1-scores\n",
        "to evaluate the logistic regression model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r24aTqpxfnQH"
      },
      "source": [
        "# S5.2: Display the confusion_matrix.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KO8P9HHCfnQN"
      },
      "source": [
        "# S5.3: Display recall, precision and f1-score values.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxU0ezJVsqvy"
      },
      "source": [
        "The f1-score is high for class `1` which are true positives are correctly obtained through Logistic Regression. But true negatives are very low. The Random Forest Classifier model is able to get more true negatives. So both of them are unable to provide high number of true positive and high number of true negatives.\n",
        "\n",
        "You will soon get to learn how both these models work behind the scenes and then you will develop a sense of which classification model to use for different kinds of problem statements.\n",
        "\n",
        "Let us predict the labels with both classifiers on some arbitrary cholesterol values, say 180 and 260."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B97SLEbh8yP5"
      },
      "source": [
        "# S5.4: Predict labels with cholesterol levels 180 and 260 for both models\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlR83AHU0ne_"
      },
      "source": [
        "Let's stop here, in the next class, we will understand the working of Logistic Regression algorithm using sigmoid function and will also try to improve the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GObBg7R3zT9g"
      },
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDyXm2kdiIgW"
      },
      "source": [
        "### **Project**\n",
        "\n",
        "You can now attempt the **Applied Tech. Project 72 - Logistic Regression - Univariate Classification I** on your own.\n",
        "\n",
        "\n",
        "**Applied Tech. Project 72 - Logistic Regression - Univariate Classification I**: https://colab.research.google.com/drive/1iHDryTxcrnUlwK69EN0OOfXDzTdTEkEK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2C9QV1GiIET"
      },
      "source": [
        "---"
      ]
    }
  ]
}
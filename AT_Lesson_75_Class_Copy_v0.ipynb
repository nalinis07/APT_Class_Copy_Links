{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nalinis07/APT_Class_Copy_Links/blob/MASTER/AT_Lesson_75_Class_Copy_v0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nreGKcypHo1M"
      },
      "source": [
        "# Lesson 75: Logistic Regression - Likelihood Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze9uSJt-I-0E"
      },
      "source": [
        "### Teacher-Student Activities\n",
        "\n",
        "In the previous class, you learnt to calculate the decision boundary by building a logistic regression model using the `sklearn` module. In this class, you will begin to learn to estimate the decision boundary purely through maths.\n",
        "\n",
        "Let's quickly go through the activities covered in the previous class and begin this class from the **Activity 1: Regularised Cost Function** section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSyqQS5T8Y1D"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vmj2glW8aKa"
      },
      "source": [
        "#### Dummy Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIBpSYJB8hsx"
      },
      "source": [
        "# Dummy dataset creation using the 'make_blob()' function.\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "features_array, target_array = make_blobs(n_samples = 1000, centers = 2, n_features = 2, random_state = 42, cluster_std = 1.25)\n",
        "\n",
        "# Object-type of the arrays created by the 'make_blob()' function and the number of rows and columns in them.\n",
        "print(f\"The features array is an {type(features_array)} object.\\nThe target array is an {type(target_array)} object.\\n\")\n",
        "print(f\"The features array has {features_array.shape[0]} rows and {features_array.shape[1]} columns.\")\n",
        "print(f\"The target array has {target_array.shape[0]} rows and {len(target_array.shape)} column.\")\n",
        "\n",
        "# Pandas DataFrame creation.\n",
        "dummy_dict = {'col 1': [features_array[i][0] for i in range(features_array.shape[0])],\n",
        "             'col 2': [features_array[i][1] for i in range(features_array.shape[0])],\n",
        "             'target': target_array}\n",
        "\n",
        "dummy_df = pd.DataFrame.from_dict(dummy_dict)\n",
        "\n",
        "# The number of occurrences of each label in the 'target' column.\n",
        "print(f\"Target counts:\\n{dummy_df['target'].value_counts()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16VQyfuGX-X4"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U-OZvfIE7W_"
      },
      "source": [
        "#### Cluster Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzn4GxEBFnMg"
      },
      "source": [
        "# Scatter plot between 'col 1' and 'col 2' columns separately for both the classes in the same plot.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize = (11, 5), dpi = 96)\n",
        "plt.scatter(dummy_df.loc[dummy_df['target'] == 0, 'col 1'], dummy_df.loc[dummy_df['target'] == 0, 'col 2'], label = 'Label 0', color = 'g')\n",
        "plt.scatter(dummy_df.loc[dummy_df['target'] == 1, 'col 1'], dummy_df.loc[dummy_df['target'] == 1, 'col 2'], label = 'Label 1', color = 'r')\n",
        "plt.xlabel('col 1', fontsize = 14)\n",
        "plt.ylabel('col 2', fontsize = 14)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TI1rKMQjc6-6"
      },
      "source": [
        "#### Calculating Coefficients Using `sklearn` Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etrA_2UW4DCj"
      },
      "source": [
        "# Coefficients Estimation by building a logistic regression model using the 'sklearn' model.\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "X = dummy_df[dummy_df.columns[:-1]] # Features\n",
        "y = dummy_df['target'] # Target\n",
        "\n",
        "def decision_boundary_coeffs(X, y):\n",
        "  logistic_reg = LogisticRegression(random_state=0).fit(X, y)\n",
        "  coef_list = list(logistic_reg.intercept_) + list(logistic_reg.coef_[0])\n",
        "  return coef_list\n",
        "\n",
        "coef_list = decision_boundary_coeffs(X, y)\n",
        "for i in range(len(coef_list)):\n",
        "  print(f\"Beta {i} = {coef_list[i]:.4f}\")\n",
        "\n",
        "# Plotting the decision boundary\n",
        "pred_col2_values = - (coef_list[0] + coef_list[1] * dummy_df['col 1']) / coef_list[2]\n",
        "\n",
        "plt.figure(figsize = (12, 5), dpi = 96)\n",
        "plt.title(\"\\n\\nClusters with Linear Decision Boundary\", fontsize = 14)\n",
        "plt.scatter(dummy_df.loc[dummy_df['target'] == 0, 'col 1'], dummy_df.loc[dummy_df['target'] == 0, 'col 2'], label = 'Label 0', color = 'g')\n",
        "plt.scatter(dummy_df.loc[dummy_df['target'] == 1, 'col 1'], dummy_df.loc[dummy_df['target'] == 1, 'col 2'], label = 'Label 1', color = 'r')\n",
        "plt.plot(dummy_df['col 1'], pred_col2_values, color = 'b', linewidth = 2, label = r\"$\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 = 0$\")\n",
        "plt.xlabel(r\"$x_1$\", fontsize = 14)\n",
        "plt.ylabel(r\"$x_2$\", fontsize = 14)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONiiHW8Mc6KM"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cyj3OiTtQG5u"
      },
      "source": [
        "#### Predictions\n",
        "\n",
        "The sigmoid function is given as\n",
        "$$p =  \\frac{1}{1 + e^{-h}}$$\n",
        "\n",
        "where\n",
        "- $p$ is the probability value between 0 and 1\n",
        "- $h$ is some relationship between $x_1, x_2, x_3, \\dots, x_n$\n",
        "- $x_1, x_2, x_3, \\dots, x_n$ are $n \\in N$ feature(s) in a dataset\n",
        "\n",
        "In this case of dummy dataset, $h = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2$\n",
        "\n",
        "$$\\therefore p =\\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2)}}$$\n",
        "\n",
        "where $\\beta_0, \\beta_1, \\beta_2$ are coefficients and $x_1, x_2$ are the independent variables.\n",
        "\n",
        "The above expression can also be written as\n",
        "\n",
        "$$p =\\frac{1}{1 + e^{-BX^T}}$$\n",
        "\n",
        "where\n",
        "\n",
        "- $X$ denotes the feature matrix i.e.\n",
        "\n",
        "  $$X = \\begin{bmatrix} 1 & x_{1,1} & x_{2,1} \\\\ 1 & x_{1,2} & x_{2,2}\\\\ 1 & x_{1,3} & x_{2,3} \\\\ \\vdots & \\vdots & \\vdots \\\\ 1 & x_{1,1000} & x_{2,1000} \\end{bmatrix}$$\n",
        "\n",
        "  Each item in the above matrix can be represented by $x_{i,j}$ where $x_{i,j}$ denotes the $j^{\\text{th}}$ item in the $i^{\\text{th}}$ column. Also the values of $i$ goes from $1$ to $2$ and the values of $j$ goes from $1$ to $1000$.\n",
        "\n",
        "- $B$ denotes the coefficients matrix i.e.\n",
        "\n",
        "  $$B = \\begin{bmatrix} \\beta_0 & \\beta_1 & \\beta_2\\end{bmatrix}$$\n",
        "\n",
        "Essentially, $$h = BX^T$$\n",
        "\n",
        "\n",
        "The above product after taking the transpose of the features matrix becomes\n",
        "\n",
        "$$h = \\begin{bmatrix} \\beta_0 & \\beta_1 & \\beta_2\\end{bmatrix} \\begin{bmatrix} 1 & 1 & 1 & \\dots & 1 \\\\ x_{1,1} & x_{1,2} & x_{1,3} & \\dots & x_{1,1000} \\\\ x_{2,1} & x_{2,2} & x_{2,3} & \\dots & x_{2,1000} \\end{bmatrix}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A5Oi179RG58"
      },
      "source": [
        "# Adding a column containing 1s to the features array.\n",
        "import numpy as np\n",
        "\n",
        "new_features_array = np.append(np.ones(shape = (features_array.shape[0], 1)), features_array, axis = 1)\n",
        "\n",
        "# Create the 'sigmoid()' function.\n",
        "def sigmoid(features_matrix, coef_matrix):\n",
        "    sigmoid_output_matrix = 1/(1 + np.exp(-1 * np.matmul(coef_matrix, np.transpose(features_matrix))))\n",
        "    return np.array(sigmoid_output_matrix)\n",
        "\n",
        "sigmoid_outputs = sigmoid(new_features_array, coef_list)\n",
        "\n",
        "# Scatter plot between the 'h' values and their corresponding sigmoid outputs.\n",
        "plt.figure(figsize = (12, 6), dpi = 96)\n",
        "plt.title(\"Scatter Plot Between \" + r\"$\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2$\" + \" and Corresponding Sigmoid Outputs\")\n",
        "plt.scatter(np.matmul(coef_list, np.transpose(new_features_array)), sigmoid_outputs)\n",
        "plt.xlabel(r'$\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2$', fontsize = 12)\n",
        "plt.ylabel(r'$\\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2)}}$', fontsize = 18)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJJiMlKv4TVJ"
      },
      "source": [
        "# Predicting the target values w.r.t. the threshold value of 0.5\n",
        "predicted_target = [1 if item >= 0.5 else 0 for item in sigmoid_outputs]\n",
        "\n",
        "# Evaluate the accuracy of the logistic regression model built through confusion matrix, precision value, recall value and f1-score.\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "print(confusion_matrix(dummy_df['target'], predicted_target), \"\\n\")\n",
        "print(classification_report(dummy_df['target'], predicted_target))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7B8vIQXXRr4"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMWohLWTc2Ji"
      },
      "source": [
        "#### Activity 1: Regularised Cost Function\n",
        "\n",
        "After building a logistic regression model using the `sklearn` module of Python, we obtained the following values of the coefficients:\n",
        "\n",
        "- $\\beta_0 = 6.3267$\n",
        "- $\\beta_1 = 1.4679$\n",
        "- $\\beta_2 = -1.3607$\n",
        "\n",
        "Now we need to obtain the same without using any Python module. For this, you will have to use the following expression (called the **regularised cost function**)\n",
        "\n",
        "$$J(\\beta) = -\\frac{1}{m} \\left[ \\sum_{i = 1}^m \\{ y_i \\log(p_i) + (1 - y_i)\\log(1 - p_i) \\} \\right]+ \\frac{\\lambda}{2m}\\sum_{j = 1}^n \\beta_j ^2$$\n",
        "\n",
        "where\n",
        "\n",
        "- $p_i = \\frac{1}{1 + e^{-h_i}}$\n",
        "\n",
        "- $h_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\dots + \\beta_n x_{in}$\n",
        "\n",
        "  In this case, $n = 2$\n",
        "\n",
        "  $\\therefore h_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2}$\n",
        "\n",
        "- $i$ is the row number in a data-frame\n",
        "\n",
        "- $m$ is the total number of rows in a data-frame\n",
        "\n",
        "- $n$ is the total number of independent variables in a data-frame\n",
        "\n",
        "- $\\lambda$ is the regularisation rate\n",
        "\n",
        "- $y$ is the actual label (or class) i.e. either $y = 0$ or $ y = 1$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oo8NvhAVmnuO"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4Fh-j2tdC71"
      },
      "source": [
        "#### Activity 2: Steps to Build Regularised Cost Function^\n",
        "\n",
        "Now let's learn how we obtained the above cost regularised cost function and how it provides the values of the coefficients.\n",
        "\n",
        "Here are the steps to be followed to estimate the coefficients.\n",
        "\n",
        "1. Consider a matrix of coefficients\n",
        "   \n",
        "   $$\\beta = \\begin{bmatrix}\\beta_0 & \\beta_1 & \\beta_2 & \\dots & \\beta_n\\end{bmatrix}$$\n",
        "\n",
        "   and another matrix of features\n",
        "   \n",
        "   $$X = \\begin{bmatrix}1 & x_{11} & x_{12} & x_{13} & \\dots & x_{1n} \\\\ 1 & x_{21} & x_{22} & x_{23} & \\dots & x_{2n} \\\\ 1 & x_{31} & x_{32} & x_{33} & \\dots & x_{3n} \\\\ \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\1 & x_{m1} & x_{m2} & x_{m3} & \\dots & x_{mn} \\\\\\end{bmatrix}$$\n",
        "\n",
        "   where $m$ is the number of records and $n$ is the number of features (or independent variables) in a dataset.\n",
        "\n",
        "2. Calculate probabilities for each record using the sigmoid function\n",
        "\n",
        "   $$p_i = \\frac{1}{1 + e^{-h_i}}$$\n",
        "\n",
        "3. Get the likelihood function\n",
        "    \n",
        "   $$L(\\beta) = \\prod_{i = 1}^m p_i^y (1 - p_i)^{(1 - y)}$$\n",
        "\n",
        "4. Get the log likelihood function\n",
        "    \n",
        "   $$J(\\beta) = \\log L(\\beta) = \\sum_{i = 1}^m \\{ y \\log p_i + (1 - y) \\log(1 - p_i) \\}$$\n",
        "\n",
        "5. Get the negative log likelihood function and divide it by the total number of records $m$\n",
        "    \n",
        "   $$J(\\beta) = -\\frac{1}{m} \\sum_{i = 1}^m \\{ y \\log p_i + (1 - y) \\log(1 - p_i) \\}$$\n",
        "\n",
        "6. Penalise the above cost function with a regularisation rate of $\\lambda$\n",
        "\n",
        "   $$J(\\beta) = -\\frac{1}{m} \\sum_{i = 1}^m \\{ y \\log p_i + (1 - y) \\log(1 - p_i) \\} + \\frac{\\lambda}{2m} \\sum_{j = 1}^n \\beta_j^2$$\n",
        "\n",
        "Let's go through the above steps one-by-one.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FocMM7UsnALX"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gyImlvPmchj"
      },
      "source": [
        "#### Activity 3: Likelihood Equation^^\n",
        "\n",
        "Consider a record $x_i$ in the $i^{\\text{th}}$ row in the features matrix.\n",
        "\n",
        "\\begin{equation}\n",
        "\\therefore x_i = \\begin{bmatrix}1 & x_{i1} & x_{i2} & x_{i3} & \\dots & x_{in}\\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "The hypothesis $h_i$ for the $i^{\\text{th}}$ record in the features matrix is\n",
        "\n",
        "\\begin{aligned}\n",
        "h_i &= \\begin{bmatrix}\n",
        "\\beta_0 & \\beta_1 & \\beta_2 & \\beta_3 & \\dots & \\beta_n\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "1 \\\\ x_{i1} \\\\ x_{i2} \\\\ x_{i3} \\\\ \\dots \\\\ x_{in}\n",
        "\\end{bmatrix} \\\\\n",
        "&= \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\beta_3 x_{i3} + \\dots + \\beta_n x_{in}\n",
        "\\end{aligned}\n",
        "\n",
        "So the corresponding probability $p_i$ for the $i^{\\text{th}}$ record in the features matrix is\n",
        "\n",
        "\\begin{aligned}\n",
        "p_i &= \\frac{1}{1 + e^{-h_i}} \\\\\n",
        " &= \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\beta_3 x_{i3} + \\dots + \\beta_n x_{in})}}\n",
        "\\end{aligned}\n",
        "\n",
        "The function $p$ is dependent on both $\\beta$ and $x$. Since $p$ is a probability, its value will range from 0 to 1.\n",
        "\n",
        "Let $y = 1$ be the label for this $i^{\\text{th}}$ record and $\\hat{y}$ be the probability calculated through the sigmoid function. Mathematically, you can say\n",
        "\n",
        "\\begin{equation}\n",
        "P(y = 1 \\space{}| \\space{} x; \\beta) = p\n",
        "\\tag{3.1}\n",
        "\\end{equation}\n",
        "\n",
        "The above expression is read as **the probability of any record having the label 1, for a given set of features ($x$) and coefficients ($\\beta$), is $p$**.\n",
        "The vertical bar i.e. $|$ is read as **given**.\n",
        "\n",
        "Consequently, the probability of a record having label **NOT 1** (or having label 0) will be $1 - p$ because the sum of probabilities is 1.\n",
        "\n",
        "So for the record $y = 0$, the equation $(3.1)$ becomes\n",
        "\n",
        "\\begin{equation}\n",
        "P(y = 0 \\space{}| \\space{} x; \\beta) = 1 - p\n",
        "\\tag{3.2}\n",
        "\\end{equation}\n",
        "\n",
        "Now, we want an equation that can combine the equations $(3.1)$ and $(3.2)$ into one single equation. The required equation is given by\n",
        "\n",
        "\\begin{equation}\n",
        "P(y \\space{} | \\space{} x; \\beta) = p^y (1 - p)^{(1 - y)}\n",
        "\\tag{3.3}\n",
        "\\end{equation}\n",
        "\n",
        "The above equation is called a **likelihood function** for one record.\n",
        "\n",
        "If you substitute, $y = 1$ in the equation $(3.3)$, you get\n",
        "\n",
        "\\begin{aligned}\n",
        "P(y = 1 \\space{} | \\space{} x) &= p(1 - p)^{1 - 1} \\\\\n",
        "\\Rightarrow P(y = 1 \\space{} | \\space{} x) &= p\n",
        "\\end{aligned}\n",
        "\n",
        "And if you substitute, $y = 0$ in the equation $(3.3)$, you get\n",
        "\n",
        "\\begin{aligned}\n",
        "P(y = 0 \\space{} | \\space{} x) &= p^0 (1 - p)^{1 - 0} \\\\\n",
        "\\Rightarrow P(y = 0 \\space{} | \\space{} x) &= 1 - p\n",
        "\\end{aligned}\n",
        "\n",
        "Now our next task is to get the log likelihood function for $m$ number of records. But before that let's learn a mathematical concept called **logarithms**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meG7Hbs91S6S"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUi975m31aYy"
      },
      "source": [
        "#### Activity 4: Logarithms^^^\n",
        "\n",
        "A logarithm (in short log) tells you the exponent of a number or how many times a number should be multiplied with itself to get another number.\n",
        "\n",
        "Eg., for how many times would you multiply $2$ with itself to obtain $32$?\n",
        "\n",
        "The answer is $5$ because\n",
        "\n",
        "\\begin{equation}\n",
        "2 \\times 2 \\times 2 \\times 2 \\times 2 = 32 \\\\\n",
        "\\tag{4.1}\n",
        "\\end{equation}\n",
        "\n",
        "or\n",
        "\n",
        "\\begin{equation}\n",
        "2^5 = 32\n",
        "\\tag{4.2}\n",
        "\\end{equation}\n",
        "\n",
        "So, mathematically, you would say that the logarithm of $32$ w.r.t. the base $2$ is $5$. It is written is\n",
        "\n",
        "\\begin{equation}\n",
        "\\log_2 32 = 5\n",
        "\\tag{4.3}\n",
        "\\end{equation}\n",
        "\n",
        "So, the equations $(4.2)$ and $(4.3)$ are the same i.e.\n",
        "\n",
        "\\begin{equation}\n",
        "2^5 = 32 \\Leftrightarrow \\log_2 32 = 5\n",
        "\\end{equation}\n",
        "\n",
        "Another eg. What should be the exponent of the base $7$ to get the number $343$. In other words, what should be the logarithm (or log) of $343$ on base $7$? Mathematically,\n",
        "\n",
        "$$\\log_7 343 = ?$$\n",
        "\n",
        "The answer is $3$ i.e. $\\log_7 343 = 3$ because $7^3 = 343$\n",
        "\n",
        "In general, the log of a number $a$ on the base $b$ is given as\n",
        "\n",
        "\\begin{equation}\n",
        "\\log_b a = c\n",
        "\\end{equation}\n",
        "\n",
        "i.e. when $b$ is multiplied $c$ times with itself (i.e. $b \\times b \\times b \\dots c \\space{} \\text{times}$), the number obtained is $a$ i.e. $b^c = a$\n",
        "\n",
        "\\begin{equation}\n",
        "\\therefore b^c = a \\Leftrightarrow \\log_b a = c\n",
        "\\end{equation}\n",
        "\n",
        "**Note:** The log is not defined for the negative numbers. Hence\n",
        "\n",
        "- $a$ should be a positive real number i.e. $a > 0$\n",
        "\n",
        "- $b$ should be a real number either between $0$ and $1$ or greater than $1$ i.e. $0 < b < 1$ or $b > 1$\n",
        "\n",
        "- Since the output of a log is an exponent of a number on a base, it squeezes the very large numbers into the smaller numbers.\n",
        "\n",
        "You may try to compute the log of a very large number, say 3,489,403,752 on a base of, say 13. For this, you can use the `log()` function of the `math` module in Python. Its syntax is\n",
        "\n",
        "**Syntax:** `math.log(number, base)`\n",
        "\n",
        "The first input to the `math.log()` function is the number for which the log is to be calculated and the second input is the base on which the log of the `number` needs to be calculated.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33HkBix4JWY4"
      },
      "source": [
        "# S4.1: Try to compute the log of a very large number say 3489403752 on a base of say 13.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVJeB92mLVSf"
      },
      "source": [
        "As you can see, the log has squeezed the very large number 3,489,403,752 to 8.567 (approx) which is a very small number compared to 3,489,403,752."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs30YCmOL36J"
      },
      "source": [
        "# S4.2: Raise the base of 13 to the power of log of 3489403752 on base 13.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qtZOQybNInO"
      },
      "source": [
        "**Log Property 1:** Here we have discovered one of the properties of log which is\n",
        "\n",
        "$$b^{\\log_b a} = a$$\n",
        "\n",
        "It says, \"**When a base is raised to the log of some number on that base, the result is the number**\".\n",
        "\n",
        "In this case, the base is $13$ and the number is $3489403752$. If you raise the base $13$ to the power of $\\log_{13} 3489403752$, you will get the $3489403752$ as the result i.e.\n",
        "\n",
        "$$13^{\\log_{13} 3489403752} = 13$$\n",
        "\n",
        "There are many more properties of logarithms that you will get to learn as the course progresses.\n",
        "\n",
        "**Most Commonly Used Base:** In general, you can compute the log of a number on any base $b$ provided $0 < b < 1$ or $b > 1$ but the most commonly used bases are $b = e$ (where $e = 2.71$) and $b = 10$.\n",
        "\n",
        "In fact, if the base is not specified in log, then $e$ is considered as the default base i.e. $\\log a$ is the same as $\\log_e a$\n",
        "\n",
        "The log with base $e$ is also written as $\\text{ln}$ which is a short-form for \"log-natural\". Therefore, $\\log \\text{a}$ is the same as $\\log_e a$ is the same as $\\text{ln a}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lihED_MnOsgM"
      },
      "source": [
        "# S4.3: Try to compute the log-natural and log to the base 10 of a very large number, say 3489403752.\n",
        "# You can use the 'numpy' module to calculate the log values on base 10 and e.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM21rHc2edKK"
      },
      "source": [
        "**Graphs of Logarithms**\n",
        "\n",
        "Let's look at the nature of graphs of logarithms and what you can interpret from these graphs.\n",
        "\n",
        "Let's create an array containing a few real numbers between 0.001 and 1000 (including both) and plot these numbers with their corresponding log values on the base 10.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31xAYeGCn6T9"
      },
      "source": [
        "# S4.4: create an array containing a few real numbers between 0.001 numbers between 0.001 and 1000 (including both).\n",
        "# Plot these numbers with their corresponding log values on the base 10.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRM43dWp2QFu"
      },
      "source": [
        "From the above graph, you can see that **when the base $b$ is greater than 1, the graph of log continuously increases as the values on the $x$-axis increase.**\n",
        "\n",
        "Also whenever $x$ is between 0 and 1 i.e. $0 < x < 1$, the corresponding log values are negative.\n",
        "\n",
        "The graph of log rises very sharply for the initial values of $x$. As the $x$ values start increasing from a particular point, the curve starts flattening.\n",
        "\n",
        "Now, let's create a graph of log when the base is less than 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47cKodxhtLn0"
      },
      "source": [
        "# S4.5: Repeat the above exercise when the base is less than 1, say b = 0.1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dA_Jimg526vd"
      },
      "source": [
        "From the above graph, you can see that **when the base $b$ is less than 1, the graph of log continuously decreases as the values on the $x$-axis increase.**\n",
        "\n",
        "Here, the graph of log drops very sharply for the initial values of $x$. As the $x$ values start increasing from a particular point, the curve starts flattening.\n",
        "\n",
        "Now you have learnt enough of logarithms to understand the log likelihood function.\n",
        "\n",
        "Let's stop here in the next class, you learn to create the log likelihood function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fx4M19oA1ZuT"
      },
      "source": [
        "---"
      ]
    }
  ]
}
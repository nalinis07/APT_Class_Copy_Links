{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nalinis07/APT_Class_Copy_Links/blob/MASTER/AT_Lesson_82_Class_Copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoxxrfkNdmSr"
      },
      "source": [
        "# Lesson 82: Support Vector Machines - Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ2n2W6mdq6P"
      },
      "source": [
        "### Teacher-Student Activities\n",
        "\n",
        "So far you have learnt linear and logistic regression in detail. In this class, you learn about support vector machines. It is another machine learning technique that can be used both for regression as well as classification. However, it is most extensively used for classification predominantly for advanced classification problems such as image classification, face detection, voice detection etc. It uses the principle of calculating decision boundaries to separate labels/classes from one another. Specifically, in the case of SVM, we call this decision boundary a **hyperplane**. So any time you hear or read the term \"hyperplane\", just in your mind replace it with a decision boundary and you won't feel lost.\n",
        "\n",
        "In this class, we are going to solve the classification of different types of flower species in the Iris Species Dataset using SVM. Let's explore the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waLPLj7DcaZv"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqGQ_YRUpbSm"
      },
      "source": [
        "### Data Description\n",
        "\n",
        "The dataset used in the problem statement, popularly known as **Iris Dataset** or **Fisher's Dataset** is published by UCI Machine Learning Repository. It contains 3 classes of 50 instances each, where each class refers to a type of Iris flower namely:\n",
        "- **Iris-setosa**\n",
        "- **Iris-virginica**\n",
        "- **Iris-versicolor**\n",
        "\n",
        "<img src = 'https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/Iris-update-1.png' width = 800>\n",
        "\n",
        "***Image Credits:*** https://en.wikipedia.org/wiki/Iris_flower_data_set\n",
        "```\n",
        "  A. Image of Iris setosa by SteinsplitterBot, used under license Attribution-Share Alike 3.0 Unported from Wikimedia Commons.\n",
        "  B. Image of Iris versicolor by Dlanglois, used under license Attribution-Share Alike 2.5 Generic from Wikimedia Commons.\n",
        "  C. Image of Iris virginica by Flickr upload bot, used under license Attribution-Share Alike 2.0 Generic from Wikimedia Commons.\n",
        "```\n",
        "\n",
        "The big idea is that based on the length and width of sepals and petals of a flower, can we build a classification model that can tell us the species of a particular Iris flower? The answer is \"Yes, we can\". This is exactly what we will do in the next few classes.\n",
        "\n",
        "The columns in the dataset are as follows:\n",
        "\n",
        "|Name|Description|\n",
        "|-|-|\n",
        "|Id| Id of the instance or record.|\n",
        "|SepalLengthCm| Length of the sepal in cm.|\n",
        "|SepalWidthCm| Width of the sepal in cm.|\n",
        "|PetalLengthCm| Length of the petal in cm.|\n",
        "|PetalWidthCm|Width of the petal in cm.|\n",
        "|Species|Name of the type of the flower|\n",
        "\n",
        "**Dataset Credits:** https://archive.ics.uci.edu/ml/datasets/iris  \n",
        "\n",
        "**Dataset Creator:** R.A. Fisher\n",
        "\n",
        "**Citation:**\n",
        "```\n",
        "Dua, D., & Graff, C.. (2017). UCI Machine Learning Repository.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgMi18G86VjO"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_eGf00TL3k3"
      },
      "source": [
        "#### Activity 1: Data Loading and Preprocessing\n",
        "\n",
        "So let's go through the routine steps before we build a classification model and explore the dataset.\n",
        "\n",
        "Link to the dataset:https://s3-student-datasets-bucket.whjr.online/whitehat-ds-datasets/iris-species.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KO_-T7xbs_-R"
      },
      "source": [
        "# S1.1: Load the dataset.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6br5tCAT7b1K"
      },
      "source": [
        "Let's look at the kind of values each of the columns have, the number of rows and columns in the dataset and whether the dataset has any missing values or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUFQSZgStJEj"
      },
      "source": [
        "# S1.2: Get the information about the dataset.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjdnGwKn76N9"
      },
      "source": [
        "Except for the last column, all the columns have floating-point values and the last column has an object-type data-type. There are 150 rows and 6 columns. And there are no missing values in the dataset because all the columns contain 150 non-null values.\n",
        "\n",
        "Now let's verify the count of each type of flower samples in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d2t_WB5uKNR"
      },
      "source": [
        "# S1.3: Get the count of each type of flower samples in the dataset.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EyjT1H98j-i"
      },
      "source": [
        "As mentioned in the data description, there are 50 samples for each type of flower.\n",
        "\n",
        "Let's add another column `Label` to the DataFrame to convert the non-numeric target column `Species` into numeric using the `map()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TJhwTArmey7"
      },
      "source": [
        "# S1.4: Add a column in the Iris DataFrame to resemble the non-numeric 'Species' column as numeric using 'map()' function.\n",
        "# Create the numeric target column 'Label' to 'iris_df' using 'map()'.\n",
        "\n",
        "# Verify the count of each type of flower samples in the 'Label' column.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjQaeqN8G8sy"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vN-4NpI-LxS"
      },
      "source": [
        "#### Activity 2: Data Visualisation^\n",
        "\n",
        "Let's look into the relationship that may exist between the features of each type of flower.\n",
        "\n",
        "Let's create a scatter plot between `SepalLengthCm` and `SepalWidthCm` columns using the `scatterplot()` function of the `seaborn` module and differentiate between the data points of different classes using the `hue` parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnSPHFeNuO2w"
      },
      "source": [
        "# S2.1: Create a scatter plot between the 'SepalLengthCm' and 'SepalWidthCm' columns using the 'scatterplot()' function of the 'seaborn' module.\n",
        "# Differentiate between the data points of different classes using the 'hue' parameter.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4qS0XGPIhUw"
      },
      "source": [
        "As it can be observed in the output above, class `Iris-setosa` can be differentiated using `SepalLengthCm` and `SepalWidthCm` but classes `Iris-virginica` and `Iris-versicolor` overlap each other.\n",
        "\n",
        "The reason being **`Iris-setosa`** has a smaller sepal length but high sepal width, **`Iris-versicolor`** has points in the middle for both sepal length and width and  **`Iris-virginica`** has high sepal length and width.\n",
        "\n",
        "Let's create a scatter plot between `PetalLengthCm` and `PetalWidthCm` columns and differentiate between the data points of different classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EdlsP-SasOI"
      },
      "source": [
        "# S2.2: Create a scatter plot between the 'SepalLengthCm' & 'SepalWidthCm' columns & differentiate between the data points of different classes.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4PtL9_DJ392"
      },
      "source": [
        "In the output, two clusters of points are separated where one cluster describes **`Iris-setosa`** and the second cluster describes the other two flower types **`Iris-versicolor`** and **`Iris-virginica`**.\n",
        "\n",
        "\n",
        "Again, the output describes the properties, where **`Iris-setosa`** has the smallest petal width and length and **`Iris-versicolor`** has average width and length and **`Iris-virginica`** has the higher petal width and length out of the three flower types\n",
        "\n",
        "Now, let's create a scatter plot for another combination between the `SepalLengthCm` and `PetalLengthCm` columns and differentiate between the data points of different classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PrBGuMTa6mv"
      },
      "source": [
        "# S2.3: Create a scatter plot between the 'SepalLengthCm' & 'PetalLengthCm' columns and differentiate between the data points of different classes.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C4F2gmER0IO"
      },
      "source": [
        "As per the properties, the output again displays two clusters where the **`Iris-setosa`** has the smallest length of the three classes, **`Iris-versicolor`** has the medium length and **`Iris-virginica`** has a high length. But due to the small margin between the medium and high length, the **`Iris-versicolor`** and **`Iris-virginica`** data points are overlapping each other.\n",
        "\n",
        "Let's create one more scatter plot for another combination between the `SepalWidthCm` and `PetalWidthCm` columns and differentiate between the data points of different classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itplBOAlbeIq"
      },
      "source": [
        "# S2.4: Create a scatter plot between the 'SepalWidthCm' and 'PetalWidthCm' columns and differentiate between the data points of different classes.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR9pzxfkZZTX"
      },
      "source": [
        "Again describing the properties, the graph has two clusters one for **`Iris-setosa`** with with high sepal width and small petal width and another for one **`Iris-versicolor`** and **`Iris-virginica`** for middle and high sepal and petal width respectively.\n",
        "\n",
        "In this graph, however, we can, of course, differentiate data points of  **`Iris-setosa`** class as well as **`Iris-versicolor`** and **`Iris-virginica`**  class from each other with only a few data points of the last two classes overlapping each other.\n",
        "\n",
        "In all four graphs, we can conclude that there is some pattern between the lengths and widths of the sepals and petals of a flower that distinguishes between the different species of Iris flower. So we can create a decision boundary to distinguish them. For this, we will use **Support Vector Machines** (**SVM**).\n",
        "\n",
        "Let's learn more about SVM in the next activity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL1-cKSjb2F7"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XpJ7jz1ch1Y"
      },
      "source": [
        "#### Activity 3: Support Vector Machines^^\n",
        "\n",
        "As mentioned at the start of this class, the Support Vector Machine is one of the machine learning algorithms used for solving classification and regression problems. **For classification, we use Support Vector Classifier (SVC) and for regression, we use Support Vector Regressor (SVR).**\n",
        "\n",
        "Just like Logistic Regression, Support Vector Classifier (SVC), also finds a decision boundary to separate the classes/labels from each other. This decision boundary is called a hyperplane.\n",
        "\n",
        "\n",
        "Now, the question is why a hyperplane?\n",
        "\n",
        "Consider the image below where a scatter plot is created for the classification of two classes (colour-coded as orange and green along with the different shapes).\n",
        "\n",
        "<img src = 'https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/misclassified-points-1.png' width = 800>\n",
        "\n",
        "A straight line (decision boundary in this case) separates the two classes marked as orange and green. However, two green samples and one orange sample is wrongly classified or misclassified.\n",
        "\n",
        "In SVM, these points are used to create a boundary around each side of the hyperplane as shown in the image below. The area enclosed between the two boundaries around a hyperplane is called a **margin**. The data points (or samples) used for the creation of these boundaries around the hyperplane are known as **Support Vectors**.\n",
        "\n",
        "<img src = 'https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/misclassified-points-2.png' width = 800 >\n",
        "\n",
        "\n",
        "**Note:** To easily understand a hyperplane in Support Vector Machines, we consider only two independent variables (or features) out of $N$. So for 2 features, a hyperplane is a straight line. For 3 features, a hyperplane is a plane and for more than 3 features, a hyperplane is some high-dimensional figure which we cannot visualise.\n",
        "\n",
        "Without any further ado, let's create our own model for SVM to classify Iris flower types.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_pcFcsEkr7P"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54AEhT8jks-V"
      },
      "source": [
        "#### Activity 4: Model Building & Kernel Trick^^^\n",
        "\n",
        "Let's create an SVM classification model using the independent features `SepalLengthCm` , `SepalWidthCm`, `PetalLengthCm` , `PetalWidthCm` and target variable as `Label` which will classify the flowers into label `0`, `1` and `2`.\n",
        "\n",
        "Support Vector Classifier can be implemented using the `SVC` class constructor of the `sklearn.svm` module.\n",
        "\n",
        "1. Import `SVC` class from the `sklearn.svm` module.\n",
        "\n",
        "2. Create `X` and `y` variable to store DataFrames containing features  (`SepalLengthCm, SepalWidthCm, PetalLengthCm, PetalWidthCm` columns) and target variable (`Label` column) respectively from the `iris_df` DataFrame.\n",
        "\n",
        "3. Using the `train_test_split()` function, split the data into training and testing sets such that the test set has 33% of one-third of the total samples.\n",
        "\n",
        "4. Create an object of the `SVC` class, say `svc_model` and pass `kernel = \"linear\"` as input to its constructor.\n",
        "\n",
        "5. Call the `fit()` function of the `SVC` class on the object created and pass `X_train` and `y_train` as inputs to the function.\n",
        "\n",
        "In the fourth step, we have used the `kernel = \"linear\"` parameter to define the kind of decision boundary to be created.\n",
        "\n",
        "**Kernel Trick:**\n",
        "\n",
        "As we learnt above, SVM classification is done in higher dimensions which requires transforming and mapping the data points in higher dimensions. To do his transformation, we need to define a parameter so that an optimum decision surface (hyperplane/decision boundary) can be created to classify the data points. Some of the major kernels for SVC are:\n",
        "\n",
        "- **I.**  Linear Kernel (`'linear'`)\n",
        "\n",
        "- **II.** Gaussian Radial Basis Function Kernel (`'rbf'`)\n",
        "\n",
        "- **III.** Polynomial Kernel (`'poly'`)\n",
        "\n",
        "Linear kernels are used for linear hyperplanes (linear classification) and RBF and polynomial kernels are used for non-linear hyperplanes (non-linear classification) for efficient and accurate models.\n",
        "\n",
        "You will learn to use different types of kernels in different problem statements as you move along in this course.\n",
        "\n",
        "Let's start with building an SVC model with a linear kernel for classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDM0-juF2F54"
      },
      "source": [
        "# S4.1: Create a model for Support Vector classification to classify the flower types into labels '1' , '2', and '3'.\n",
        "# Import all the libraries\n",
        "\n",
        "# Create X and y variables\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "\n",
        "# Create the SVC model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVSdR3QFO6RF"
      },
      "source": [
        "The accuracy score is 97% for the Support Vector Classifier (SVC) linear model. However, let's make the predictions on the train set and compare them with the actual labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfJhe8nxiRPl"
      },
      "source": [
        "# S4.2: Make predictions on the train dataset by using the 'predict()' function.\n",
        "# Compute the predictions\n",
        "\n",
        "# Print the occurrence of each flower type computed in the predictions.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_haHA0Wpih9m"
      },
      "source": [
        "All three labels have been identified by the SVC model. Let's repeat the above exercise for the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZrjCTSl6zXM"
      },
      "source": [
        "# S4.3: Make predictions on the test dataset by using the 'predict()' function.\n",
        "# Compute the predictions\n",
        "\n",
        "# Print the occurrence of each flower type computed in the predictions.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUWZiyrF0EE-"
      },
      "source": [
        "As it can be observed all three labels are identified. Let's create a confusion matrix to calculate True Positives, False Positives, True Negatives and False Negatives to evaluate the SVC linear model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPSbaZxe6zXN"
      },
      "source": [
        "# S4.4: Create a confusion matrix for the test set.\n",
        "# Import the libraries\n",
        "\n",
        "# Print the confusion matrix\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHk-nyeiPe3a"
      },
      "source": [
        "The confusion matrix displays that there are no misclassifications.\n",
        "\n",
        "Let's print the classification report to observe the recall, precision and f1-scores for linear SVC on Iris DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDbrsVSd6zXN"
      },
      "source": [
        "# S4.5: Display recall, precision and f1-score values for the test set.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkD_H5pjR3Zn"
      },
      "source": [
        "The f1-scores for the classes are exactly 1. This means the SVC model has classified all the species of the Iris flower correctly.\n",
        "\n",
        "Let's stop here. In the next class, you will learn to visualise the hyperplanes created by SVC to distinguish between different species of the Iris flower.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZE5v78q9RqtA"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NnqlqLY05s9"
      },
      "source": [
        "### **Project**\n",
        "You can now attempt the **Applied Tech. Project 82 - Support Vector Machines** on your own.\n",
        "\n",
        "**Applied Tech. Project 82 - Support Vector Machines**: https://colab.research.google.com/drive/1HsyTHufbM712sZgbcahy6EEwPQnnobrU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7bYS1rW1Agh"
      },
      "source": [
        "---"
      ]
    }
  ]
}